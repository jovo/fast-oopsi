\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{YusteKonnerth06}
\citation{NagayamaChen07}
\citation{GobelHelmchen07}
\citation{LuoSvoboda08}
\citation{GaraschukKonnerth07}
\citation{MankGriesbeck08}
\citation{WallaceHasan08}
\citation{OhkiReid06}
\citation{KerrHelmchen07}
\citation{GreenbergKerr08}
\citation{HolekampHoly08}
\citation{VogelsteinPaninski09b}
\citation{LeeSeung99}
\citation{LeeSeung01}
\citation{HuysPaninski06}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\@writefile{toc}{\contentsline {paragraph}{Motivation}{3}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Limitations of calcium imaging}{3}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Computational tools as important as experimental tools}{3}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Previous approaches}{3}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{Our approach}{3}{section*.6}}
\citation{YusteKonnerth06}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{4}{section.2}}
\newlabel{sec:methods}{{2}{4}{Methods\relax }{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data driven generative model}{4}{subsection.2.1}}
\newlabel{sec:model}{{2.1}{4}{Data driven generative model\relax }{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A typical in vitro data set suggests that a reasonable first order model may be constructed by convolving the spike train with an exponential, and adding Gaussian noise. Top panel: the average (over frames) of a typical field-of-view. Bottom left: spike train (black bars), convolved with an exponential (gray line), superimposed on the one-dimensional fluorescence time series (black line). Bottom right: a histogram of the residual error between the gray and black lines from the bottom left panel (black line), and the best fit Gaussian (gray line).}}{5}{figure.1}}
\newlabel{fig:in_vitro_ex}{{1}{5}{Data driven generative model\relax }{figure.1}{}}
\newlabel{eq:F}{{1}{5}{Data driven generative model\relax }{equation.1}{}}
\newlabel{eq:C}{{2}{5}{Data driven generative model\relax }{equation.2}{}}
\citation{??}
\citation{Wiener49}
\citation{HolekampHoly08}
\newlabel{eq:n}{{3}{6}{Data driven generative model\relax }{equation.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Goal}{6}{subsection.2.2}}
\newlabel{sec:goal}{{2.2}{6}{Goal\relax }{subsection.2.2}{}}
\newlabel{eq:nhat1}{{4}{6}{Goal\relax }{equation.4}{}}
\newlabel{eq:ssm}{{5}{6}{Goal\relax }{equation.5}{}}
\newlabel{eq:obj}{{6}{6}{Goal\relax }{equation.6}{}}
\newlabel{eq:nhat2}{{6a}{6}{Goal\relax }{equation.6a}{}}
\newlabel{eq:nhat2}{{6b}{6}{Goal\relax }{equation.6b}{}}
\newlabel{eq:MAP}{{7}{6}{Goal\relax }{equation.7}{}}
\citation{HastieFriedman01}
\citation{BoydVandenberghe04}
\citation{BoydVandenberghe04}
\citation{BoydVandenberghe04}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Approximating a Poisson distribution. Left panel: when $\lambda $ is small (e.g., $\approx 1$), an exponential distribution (dashed gray line) approximates the Poisson distribution (solid black line) well, but a Gaussian distribution (dash-dotted gray line) does not. Right panel: when $\lambda $ is large (e.g., $\approx 20$), the inverse is true.}}{7}{figure.2}}
\newlabel{fig:dist_comp}{{2}{7}{Goal\relax }{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Inference}{7}{subsection.2.3}}
\newlabel{sec:inf}{{2.3}{7}{Inference\relax }{subsection.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{FAst Non-negative Deconvolution (FANSI) Filter}{7}{section*.7}}
\newlabel{eq:C2}{{8}{7}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.8}{}}
\newlabel{eq:obj2}{{9}{7}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.9}{}}
\newlabel{eq:eta}{{10}{7}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.10}{}}
\newlabel{eq:eta2}{{11}{8}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.11}{}}
\newlabel{eq:eta3}{{12}{8}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.12}{}}
\newlabel{eq:M}{{13}{8}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.13}{}}
\newlabel{eq:NR}{{14}{8}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.14}{}}
\newlabel{eq:g}{{14c}{8}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.14c}{}}
\newlabel{eq:H}{{14d}{8}{FAst Non-negative Deconvolution (FANSI) Filter\relax }{equation.14d}{}}
\@writefile{toc}{\contentsline {paragraph}{Fast Wiener Filter}{8}{section*.8}}
\newlabel{eq:C3}{{15}{8}{Fast Wiener Filter\relax }{equation.15}{}}
\newlabel{eq:obj3}{{16}{9}{Fast Wiener Filter\relax }{equation.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Assessment}{9}{subsection.2.4}}
\newlabel{sec:ass}{{2.4}{9}{Assessment\relax }{subsection.2.4}{}}
\newlabel{eq:SNR}{{17}{9}{Assessment\relax }{equation.17}{}}
\newlabel{eq:MSE}{{18}{9}{Assessment\relax }{equation.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Experimental Methods}{9}{subsection.2.5}}
\newlabel{sec:exp}{{2.5}{9}{Experimental Methods\relax }{subsection.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{10}{section.3}}
\newlabel{sec:results}{{3}{10}{Results\relax }{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Main Result}{10}{subsection.3.1}}
\newlabel{sec:main}{{3.1}{10}{Main Result\relax }{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A simulation demonstrating the performance of the FANSI filter in different firing regimes. The left panels show that in the sparse firing regime, the FANSI filter outperforms the Wiener filter in terms of SNR. This follows because an exponential is a closer approximation to a Poisson than a Gaussian, when spiking is sparse. The right panels show that both approximations are good in the fast firing regime. Top left panel: fluorescence time series for a neuron with a slow firing rate. Middle left panel: the FANSI filter's inferred spike train. Bottom left panel: Wiener filter's inferred spike train. Note that (i) the Wiener filter does not impose a non-negativity constraint, and (ii) the effective SNR of the Wiener filter in this example is worse than the FANSI filter's. Top right panel: same as top left panel, for a neuron with a high firing rate. Middle right panel: the FANSI filter's inferred spike train smoothed with a Gaussian kernel for visualization purposes (black line), and the true spike train smoothed with the same Gaussian kernel (gray line). Bottom right panel: same as middle right panel, but with the Wiener filter. Parameters for left panels: same as in Figure \ref  {fig:schem}. Parameters for right panels: same as Figure \ref  {fig:schem}, except: $\sigma =8$ photons, $\lambda =500$ Hz.}}{11}{figure.3}}
\newlabel{fig:wiener}{{3}{11}{Main Result\relax }{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Quantitative assessment of the FANSI filter's inference quality and speed. The left columns show that the FANSI filter outperforms the Wiener filter in terms of eSNR --- Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:SNR}\unskip \@@italiccorr )}} --- regardless of variance of observation noise (top) and expected firing rate (bottom). The top right panel show that when noise is low, even when firing rates are relatively (e.g. $\lambda \Delta =20$ Hz), the FANSI filter and Wiener filter both perform well. Both algorithms scale linearly with the number of image frames, meaning that it takes about 1 second of computational time per 50,000 image frames, using either algorithm. Simulation details: 5 simulations for each point on all the plots, mean (solid line) and standard deviation (bars) are shown for each. Parameters: $\Delta = 0.005$ sec, $\alpha =1$, $\beta =0$. Top left: $\lambda =1$ Hz, $\tau =1$ sec. Top right: $\lambda =10$ Hz, $\tau =1$ sec. Bottom left: $\sigma =0.25$, $\tau =0.5$ sec. Bottom right: $\sigma =0.25$, $\tau =0.1$ sec, $\lambda =1$ Hz.}}{12}{figure.4}}
\newlabel{fig:stats}{{4}{12}{Main Result\relax }{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The tuning curve of a neuron (black line), estimating from the true spike train (gray line), and the inferred spike train using the (i) FANSI filter (blue line), (ii) Wiener filter (red line), and (iii) dF/F. Clearly, the FANSI filter performs nearly as well as the true spike train, whereas the Wiener filter and dF/F do not. Note that half-wave rectification of the Wiener did not change the results at all. Simulation details: mean (solid lines) and standard deviation (bars) of 5 simulations,$T=800$, $\Delta =0.005$ sec, $\alpha =1$, $\beta =0$, $\tau =0.1$ sec, $x_{i,t} \sim \@mathcal {U}(0,0.2)$, $\sigma =0.25$.}}{13}{figure.5}}
\newlabel{fig:kernel}{{5}{13}{Main Result\relax }{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Spatial Filtering}{14}{subsection.3.2}}
\newlabel{sec:spatial}{{3.2}{14}{Spatial Filtering\relax }{subsection.3.2}{}}
\newlabel{eq:bF}{{19}{14}{Spatial Filtering\relax }{equation.19}{}}
\newlabel{eq:eta4}{{20}{14}{Spatial Filtering\relax }{equation.20}{}}
\newlabel{eq:g2}{{21}{14}{Spatial Filtering\relax }{equation.21}{}}
\newlabel{eq:H2}{{22}{14}{Spatial Filtering\relax }{equation.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A simulation demonstrating that using a better spatial filter can significantly enhance the effective SNR (see Supplementary Movie 1 for the full movie associated with this simulation). Top left: true spatial filter. Top second from left: mean frame. Top second from right: typical spatial filter. Top right: example frame from move (frame number 100). Middle left: 1-dimensional fluorescence projection using typical spatial filter. Bottom left: $\boldsymbol  {n}^{FANSI}$ using typical spatial filter. Middle right: 1-dimensional fluorescence projection using true spatial filter. Bottom right: $\boldsymbol  {n}^{FANSI}$ using true spatial filter. Simulation details: $\boldsymbol  {\alpha }=\@mathcal {N}(\boldsymbol  {0},2 \boldsymbol  {I})-1.1 \@mathcal {N}(\boldsymbol  {0},2.5 \boldsymbol  {I})$ where $\@mathcal {N}(\boldsymbol  {mu},\boldsymbol  {\Sigma })$ indicates a Gaussian with mean $\boldsymbol  {\mu }$ and covariance matrix $\boldsymbol  {\Sigma }$, $\boldsymbol  {\beta }=1$, $\tau =0.85$ sec, $\lambda =5$ Hz.}}{15}{figure.6}}
\newlabel{fig:spatial}{{6}{15}{Spatial Filtering\relax }{figure.6}{}}
\citation{VogelsteinPaninski09b}
\citation{Rabiner89}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Learning}{16}{subsection.3.3}}
\newlabel{sec:learn}{{3.3}{16}{Learning\relax }{subsection.3.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Initializing the parameters}{16}{section*.9}}
\@writefile{toc}{\contentsline {paragraph}{Estimating the parameters given $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \boldsymbol  {n}$}\mathaccent "0362{\boldsymbol  {n}}$}{16}{section*.10}}
\newlabel{eq:par1}{{23}{16}{Estimating the parameters given $\hbn $\relax }{equation.23}{}}
\newlabel{eq:par2}{{24}{16}{Estimating the parameters given $\hbn $\relax }{equation.24}{}}
\citation{YaksiFriedrich07}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A simulation demonstrating that given only the fluorescence movie, the parameters may be estimated, and the spike train inferred (c.f. Supplementary Movie 2). Top left panel: true spatial filter. Middle left panel: projection of movie onto true spatial filter. Bottom left panel: inferred spike train using true parameters. Right panels: same as left except estimating parameters. All parameters estimated other than $\gamma $, which was assumed known. Parameters converged within 7 iterations. Simulation details: $T=1000$, $\Delta =5$ msec, $\boldsymbol  {\alpha }$ is the same as in Figure \ref  {fig:spatial}, $\beta =0$, $\tau =500$ msec, $\lambda =10$ Hz.}}{18}{figure.7}}
\newlabel{fig:spatial_EM}{{7}{18}{Estimating the parameters given $\hbn $\relax }{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}in vitro data}{19}{subsection.3.4}}
\newlabel{sec:vitro}{{3.4}{19}{in vitro data\relax }{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Overlapping spatial filters}{20}{subsection.3.5}}
\newlabel{sec:overlap}{{3.5}{20}{Overlapping spatial filters\relax }{subsection.3.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Model}{20}{section*.11}}
\@writefile{toc}{\contentsline {paragraph}{Inference}{20}{section*.12}}
\newlabel{eq:M2}{{30}{20}{Inference\relax }{equation.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Learning}{20}{section*.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Simulation showing that even when two neuron's spatial filters are largely overlapping}}{21}{figure.8}}
\newlabel{fig:spatial_multi}{{8}{21}{Learning\relax }{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Population imaging}{22}{subsection.3.6}}
\newlabel{sec:pop}{{3.6}{22}{Population imaging\relax }{subsection.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces full movie, in vitro data}}{22}{figure.9}}
\newlabel{fig:spatial_full_data}{{9}{22}{Population imaging\relax }{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Slow rise time}{23}{subsection.3.7}}
\newlabel{sec:slow}{{3.7}{23}{Slow rise time\relax }{subsection.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Slow rise time}}{23}{figure.10}}
\newlabel{fig:slow}{{10}{23}{Slow rise time\relax }{figure.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Poisson observation model}{24}{subsection.3.8}}
\newlabel{sec:poisson}{{3.8}{24}{Poisson observation model\relax }{subsection.3.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Model}{24}{section*.14}}
\@writefile{toc}{\contentsline {paragraph}{Inference}{24}{equation.33}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Poisson}}{24}{figure.11}}
\newlabel{fig:poiss}{{11}{24}{Inference\relax }{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}in vivo data}{25}{subsection.3.9}}
\newlabel{sec:vivo}{{3.9}{25}{in vivo data\relax }{subsection.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Given only a fluorescence movie, recorded in vivo, we can learn the parameters necessary to correctly infer the spike trains. Left: mean frame. Left: projection of movie onto mean frame. Left: the FANSI filter's inference.}}{25}{figure.12}}
\newlabel{fig:spatial_data}{{12}{25}{in vivo data\relax }{figure.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{26}{section.4}}
\newlabel{sec:dis}{{4}{26}{Discussion\relax }{section.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Summary}{26}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{Extensions}{26}{section*.17}}
\@writefile{toc}{\contentsline {paragraph}{Thresholding}{26}{section*.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Incorporating a nonlinear observation model}{27}{subsection.4.1}}
\newlabel{sec:nonlin}{{4.1}{27}{Incorporating a nonlinear observation model\relax }{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Saturation}}{27}{figure.13}}
\newlabel{fig:satur}{{13}{27}{Incorporating a nonlinear observation model\relax }{figure.13}{}}
\bibdata{/Users/joshyv/Research/misc/biblist}
\bibcite{YusteKonnerth06}{1}
\bibcite{NagayamaChen07}{2}
\bibcite{GobelHelmchen07}{3}
\bibcite{LuoSvoboda08}{4}
\bibcite{GaraschukKonnerth07}{5}
\bibcite{MankGriesbeck08}{6}
\bibcite{WallaceHasan08}{7}
\bibcite{OhkiReid06}{8}
\bibcite{KerrHelmchen07}{9}
\bibcite{GreenbergKerr08}{10}
\bibcite{HolekampHoly08}{11}
\bibcite{VogelsteinPaninski09b}{12}
\bibcite{LeeSeung99}{13}
\bibcite{LeeSeung01}{14}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Dynamic prior}{28}{subsection.4.2}}
\@writefile{toc}{\contentsline {paragraph}{Model}{28}{section*.19}}
\@writefile{toc}{\contentsline {paragraph}{Inference}{28}{equation.36}}
\@writefile{toc}{\contentsline {paragraph}{Acknowledgments}{28}{section*.21}}
\bibcite{HuysPaninski06}{15}
\bibcite{Wiener49}{16}
\bibcite{HastieFriedman01}{17}
\bibcite{BoydVandenberghe04}{18}
\bibcite{Rabiner89}{19}
\bibcite{YaksiFriedrich07}{20}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {section}{References}{29}{section*.22}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Wiener Filter}{29}{section.A}}
\newlabel{sec:wiener}{{A}{29}{Wiener Filter\relax }{section.A}{}}
\newlabel{eq:w1}{{37}{29}{Wiener Filter\relax }{equation.37}{}}
\newlabel{eq:w2}{{38}{29}{Wiener Filter\relax }{equation.38}{}}
\newlabel{eq:w_par}{{41a}{29}{Wiener Filter\relax }{equation.41a}{}}
