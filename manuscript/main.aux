\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{GreenbergKerr08}
\citation{HolekampHoly08}
\citation{VogelsteinPaninski09}
\citation{LeeSeung99}
\citation{HuysPaninski06}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{ImagingManual}
\citation{VogelsteinPaninski09}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}{section.2}}
\newlabel{sec:methods}{{2}{2}{Methods\relax }{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data driven generative model}{2}{subsection.2.1}}
\newlabel{sec:model}{{2.1}{2}{Data driven generative model\relax }{subsection.2.1}{}}
\newlabel{eq:F}{{1}{2}{Data driven generative model\relax }{equation.1}{}}
\newlabel{eq:C}{{2}{2}{Data driven generative model\relax }{equation.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A typical in vitro data-set suggests that a reasonable first order model may be constructed by convolving the spike train with an exponential, and adding Gaussian noise. Top panel: the average (over frames) of a typical field-of-view. Bottom left: spike train (black bars), convolved with an exponential (gray line), superimposed on the one-dimensional fluorescence time series (black line). Bottom right: a histogram of the residual error between the gray and black lines from the bottom left panel (black line), and the best fit Gaussian (gray line).}}{3}{figure.1}}
\newlabel{fig:in_vitro_ex}{{1}{3}{Data driven generative model\relax }{figure.1}{}}
\newlabel{eq:n}{{3}{3}{Data driven generative model\relax }{equation.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Goal}{3}{subsection.2.2}}
\newlabel{sec:goal}{{2.2}{3}{Goal\relax }{subsection.2.2}{}}
\newlabel{eq:nhat1}{{4}{3}{Goal\relax }{equation.4}{}}
\citation{PaninskiWu09}
\citation{CONV04}
\citation{CONV04}
\citation{CONV04}
\newlabel{eq:bayes}{{5}{4}{Goal\relax }{equation.5}{}}
\newlabel{eq:nhat2}{{6}{4}{Goal\relax }{equation.6}{}}
\newlabel{eq:post1}{{7}{4}{Goal\relax }{equation.7}{}}
\newlabel{eq:lik1}{{7a}{4}{Goal\relax }{equation.7a}{}}
\newlabel{eq:prior1}{{7b}{4}{Goal\relax }{equation.7b}{}}
\newlabel{eq:post2}{{8}{4}{Goal\relax }{equation.8}{}}
\newlabel{eq:lik2}{{8a}{4}{Goal\relax }{equation.8a}{}}
\newlabel{eq:prior2}{{8b}{4}{Goal\relax }{equation.8b}{}}
\newlabel{eq:obj}{{9}{4}{Goal\relax }{equation.9}{}}
\newlabel{eq:obj1}{{9a}{4}{Goal\relax }{equation.9a}{}}
\newlabel{eq:logobj1}{{9b}{4}{Goal\relax }{equation.9b}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Inference}{4}{subsection.2.3}}
\newlabel{sec:inf}{{2.3}{4}{Inference\relax }{subsection.2.3}{}}
\citation{CONV04}
\newlabel{eq:obj2}{{10}{5}{Inference\relax }{equation.10}{}}
\newlabel{eq:eta}{{11}{5}{Inference\relax }{equation.11}{}}
\newlabel{eq:eta2}{{12}{5}{Inference\relax }{equation.12}{}}
\newlabel{eq:M}{{13}{5}{Inference\relax }{equation.13}{}}
\newlabel{eq:eta3}{{14}{5}{Inference\relax }{equation.14}{}}
\newlabel{eq:NR}{{15}{5}{Inference\relax }{equation.15}{}}
\newlabel{eq:g}{{15a}{5}{Inference\relax }{equation.15a}{}}
\newlabel{eq:H}{{15b}{5}{Inference\relax }{equation.15b}{}}
\citation{YaksiFriedrich06}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Learning}{6}{subsection.2.4}}
\newlabel{sec:learn}{{2.4}{6}{Learning\relax }{subsection.2.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Initializing the parameters}{6}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{Estimating the parameters given $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \boldsymbol  {n}$}\mathaccent "0362{\boldsymbol  {n}}$}{6}{section*.2}}
\newlabel{eq:par1}{{16}{6}{Estimating the parameters given $\hbn $\relax }{equation.16}{}}
\newlabel{eq:par2}{{17}{6}{Estimating the parameters given $\hbn $\relax }{equation.17}{}}
\newlabel{eq:par2}{{18}{6}{Estimating the parameters given $\hbn $\relax }{equation.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Convergence criteria}{7}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Spatial filtering}{7}{subsection.2.5}}
\newlabel{sec:spatial}{{2.5}{7}{Spatial filtering\relax }{subsection.2.5}{}}
\newlabel{eq:bF}{{20}{7}{Spatial filtering\relax }{equation.20}{}}
\newlabel{eq:eta4}{{21}{7}{Spatial filtering\relax }{equation.21}{}}
\newlabel{eq:g2}{{22}{7}{Spatial filtering\relax }{equation.22}{}}
\newlabel{eq:H2}{{23}{7}{Spatial filtering\relax }{equation.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Overlapping spatial filters}{7}{subsection.2.6}}
\newlabel{sec:methods:overlapping}{{2.6}{7}{Overlapping spatial filters\relax }{subsection.2.6}{}}
\newlabel{eq:M2}{{26}{7}{Overlapping spatial filters\relax }{equation.26}{}}
\citation{MacLeanYuste05}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Experimental Methods}{8}{subsection.2.7}}
\newlabel{sec:exp}{{2.7}{8}{Experimental Methods\relax }{subsection.2.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Slice Preparation and Imaging}{8}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Electrophysiology}{8}{section*.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{8}{section.3}}
\newlabel{sec:results}{{3}{8}{Results\relax }{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Main Result}{8}{subsection.3.1}}
\newlabel{sec:main}{{3.1}{8}{Main Result\relax }{subsection.3.1}{}}
\citation{PologrutoSvoboda04}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The fast filter significantly outperforms the optimal linear deconvolution (aka, Wiener) filter on typical simulated data-sets. Top panel: fluorescence trace. Second panel: spike train. Third panel: fast filter inference. Bottom panel: Wiener filter inference. Gray '$+$'s in bottom two panels indicate true spike times. Simulation details: $T=2930$ time steps, $\Delta =5$ msec, $\alpha =1$, $\beta =0$, $\sigma =0.3$, $\tau =1$ sec, $\lambda =1$ Hz.}}{9}{figure.2}}
\newlabel{fig:woopsi_inf}{{2}{9}{Main Result\relax }{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Online analysis of spike trains using the fast filter}{9}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Extensions}{9}{subsection.3.3}}
\newlabel{eq:nonlin}{{29}{9}{Extensions\relax }{equation.29}{}}
\citation{VogelsteinPaninski09}
\citation{VogelsteinPaninski09}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The fast filter significantly outperforms the Wiener filter, even when estimating the parameters only from the observed data. Simulated details as in Figure \ref  {fig:woopsi_inf}.}}{10}{figure.3}}
\newlabel{fig:woopsi_learn}{{3}{10}{Main Result\relax }{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Spatial filter}{10}{subsection.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The fast filter significantly outperforms the Wiener filter on typical in vitro data-sets. Note that all the parameters for both filters were estimated from the data.}}{11}{figure.4}}
\newlabel{fig:woopsi_data}{{4}{11}{Main Result\relax }{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Applying the fast filter in real time to a large population of neurons imaged simultaneously. The inferred spike trains convey much more clearly the neural activity. Left panel: Mean segmented image field. Middle panel: example fluorescence traces. Right panel: fast filter output corresponding to each associated trace.}}{11}{figure.5}}
\newlabel{fig:pop}{{5}{11}{Online analysis of spike trains using the \foopsi filter\relax }{figure.5}{}}
\citation{Hoyer04}
\citation{OGradyPearlmutter06}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The fast filter effectively initializes the parameters for the SMC filter (which outperforms the fast filter), significantly reducing the number of expectation-maximization iterations to convergence. Note that the ordinate on the bottom panel corresponds to the probability of a spike having occurred in each frame.}}{12}{figure.6}}
\newlabel{fig:smc_init}{{6}{12}{Extensions\relax }{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Overlapping spatial filters}{12}{subsection.3.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{12}{section.4}}
\newlabel{sec:dis}{{4}{12}{Discussion\relax }{section.4}{}}
\citation{VogelsteinPaninski09}
\citation{MishchenkoPaninski09}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A simulation demonstrating that using a better spatial filter can significantly enhance the effective SNR (see Supplementary Movie 1 for the full movie associated with this simulation). The true spatial filter was a sum of Gaussians: a positively weighted small variance Gaussian, and a negatively weighted large variance Gaussian (both with the same mean). Top row far left: true spatial filter. Top row second from left: example frame (frame number 100). Top row second from right: typical spatial filter. Top row far right: mean frame. Middle row left: fluorescence trace using typical spatial filter. Bottom row left: fast filter output using typical spatial filter. Middle row right: fluorescence trace using true spatial filter. Bottom right: fast filter output using true spatial filter. Simulation details: $\mathaccentV {vec}17E{\alpha }=\@mathcal {N}(\boldsymbol  {0},2 \boldsymbol  {I})-1.1 \@mathcal {N}(\boldsymbol  {0},2.5 \boldsymbol  {I})$ where $\@mathcal {N}(\boldsymbol  {mu},\boldsymbol  {\Sigma })$ indicates a Gaussian with mean $\boldsymbol  {\mu }$ and covariance matrix $\boldsymbol  {\Sigma }$, $\boldsymbol  {\beta }=1$, $\tau =0.85$ sec, $\lambda =5$ Hz.}}{13}{figure.7}}
\newlabel{fig:spatial}{{7}{13}{Spatial filter\relax }{figure.7}{}}
\bibdata{/Users/joshyv/Research/misc/biblist}
\bibcite{GreenbergKerr08}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Simulation showing that even when two neurons' spatial filters are overlapping, one can separate the two signals by spatial filtering. Simulation details: $\mathaccentV {vec}17E{\alpha }^1=\@mathcal {N}([-1.8 1.8],2 \boldsymbol  {I})\tmspace  +\thinmuskip {.1667em} \mathaccentV {vec}17E{\alpha }^2=\@mathcal {N}([1.8 -1.8],5 \boldsymbol  {I})$, $\boldsymbol  {\beta }=[1 1]^{\ensuremath  {\@mathsf {T}}}$, $\tau =[0.5 0.5]^{\ensuremath  {\@mathsf {T}}}$ sec, $\lambda =[1.5 1.5]$ Hz.}}{14}{figure.8}}
\newlabel{fig:spatial_multi_inf}{{8}{14}{Overlapping spatial filters\relax }{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Simulation showing that even when two neuron's spatial filters are largely overlapping, the spatial filter of each can be inferred, to separate the two signals. Simulation details as above.}}{14}{figure.9}}
\newlabel{fig:spatial_multi_learn}{{9}{14}{Overlapping spatial filters\relax }{figure.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Acknowledgments}{14}{section*.6}}
\bibcite{HolekampHoly08}{2}
\bibcite{VogelsteinPaninski09}{3}
\bibcite{LeeSeung99}{4}
\bibcite{HuysPaninski06}{5}
\bibcite{ImagingManual}{6}
\bibcite{PaninskiWu09}{7}
\bibcite{CONV04}{8}
\bibcite{YaksiFriedrich06}{9}
\bibcite{MacLeanYuste05}{10}
\bibcite{PologrutoSvoboda04}{11}
\bibcite{Hoyer04}{12}
\bibcite{OGradyPearlmutter06}{13}
\bibcite{MishchenkoPaninski09}{14}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {section}{References}{15}{section*.7}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Wiener Filter}{15}{section.A}}
\newlabel{sec:wiener}{{A}{15}{Wiener Filter\relax }{section.A}{}}
\newlabel{eq:obj3}{{31}{15}{Wiener Filter\relax }{equation.31}{}}
\newlabel{eq:w2}{{32}{16}{Wiener Filter\relax }{equation.32}{}}
