Given the above model, our goal is to find the maximum \emph{a posteriori} (MAP) spike train, i.e., the most likely spike train, $\bn$,  given the fluorescence measurements, $\bF$. Formally, we have:

\begin{subequations}  \label{eq:obj}
\begin{align}
\bn_{MAP}
&=  \anx P[\bn | \bF] \label{eq:nhat1} \\
&= \anx P[\bF | \bn] P[\bn]  \label{eq:nhat2} \\
&= \argmax_{n_t \in \mathbb{N}_0 \forall t} \prod_{t=1}^T  P[F_t | C_t]  P[n_t] 
= \argmax_{n_t \in \mathbb{N}_0 \forall t} \sum_{t=1}^T \big( \log P[F_t | C_t] + \log P[n_t]\big)  \label{eq:nhat3} %\\
%&= \ann  \sum_{t=1}^T \bigg( \frac{1}{2 \sig^2}(F_t - \alpha(C_t + \beta))^2  -  n_t \log \lam \Del + \log n_t! \bigg), \label{eq:nhat4}   
\end{align} 
\end{subequations}

\noindent where \ref{eq:nhat1} is the definition of the MAP spike train, \ref{eq:nhat2} follows from Bayes' Rule, \ref{eq:nhat3} follows from the state-space nature of our problem, $\mathbb{N}_0$ is the set of natural numbers (i.e., $\mathbb{N}_0 = \{0, 1, 2, \ldots\}$), $T$ is the number of time steps in the recording, and $C_t$ is implicitly a function of $n_t$.  Plugging Eqs. \eqref{eq:F} and \eqref{eq:C} into Eq. \eqref{eq:nhat3} yields:

\begin{align} \label{eq:MAP}
\bn_{MAP} &= \ann  \sum_{t=1}^T \bigg( \frac{1}{2 \sig^2}(F_t - \alpha(C_t + \beta))^2  -  n_t \log \lam \Del + \log n_t! \bigg), 
\end{align} 

\noindent Unfortunately, solving Eq. \eqref{eq:MAP} exactly is computationally intractable, as it requires a nonlinear search over all possible spike trains (and since $n_t \in \mathbb{N}_0$, there are an infinite number of them).  We could restrict our search space by imposing an upper bound, $k$, on the number of spikes within a frame.  However, in that case, the computational complexity scales \emph{exponentially} with the number of image frames --- more specifically, requires $O(k^T)$ time --- which for pragmatic reasons is intractable.  Thus, we approximate Eq. \eqref{eq:MAP}, by modifying Eq. \eqref{eq:C}, replacing the Poisson distribution with one that yields a log-concave problem.  This reduces the algorithmic complexity from requiring a search over $O(k^T)$ possible spike trains, to some kind of gradient ascent solution.  

Two distributions naturally arise as possible approximations to a Poisson: (i) exponential, and (ii) Gaussian.  As depicted in Figure \ref{fig:dist_comp}  an exponential distribution (dashed gray line) is an excellent approximation to the Poisson distribution (solid black line), when $\lam$ is small (left panel).  On the other hand, when $\lam$ is large, a Gaussian distribution (dash-dotted gray line) closely approximates a Poisson when $\lam$ is large (right panel). Thus, \nai vely, it seems as though it may be desirable to use a Gaussian approximation when the neuron is firing with a high firing rate, and approximate the Poisson with an exponential when the neuron is firing sparsely.  The Wiener filter is, in fact, the optimal filter given the Gaussian approximation \cite{Wiener49} (see \cite{HolekampHoly08} for an application of the Wiener filter to this problem).  Below, we develop an algorithm to perform inference given the exponential distribution.  

\begin{figure}[H]
\centering \includegraphics[width=.9\linewidth]{../figs/dist_comp}
\caption{Approximating a Poisson distribution.  Left panel: when $\lam$ is small (e.g., $\approx 1$), an exponential distribution (dashed gray line) approximates the Poisson distribution (solid black line) well, but a Gaussian distribution (dash-dotted gray line) does not.  Right panel: when $\lam$ is large (e.g., $\approx 20$), the inverse is true.} \label{fig:dist_comp}
\end{figure}