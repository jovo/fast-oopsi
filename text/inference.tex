\paragraph{FAst Non-negative Deconvolution (FAND) Filter}

Our goal here is to develop an algorithm to efficiently approximate $\hbn_{MAP}$.  The main contribution of this work demonstrating that we can substitute the Poisson distribution with an exponential distribution, reducing computational complexity from $O(k^T)$ to $O(T)$.  Formally, we replace Eq. \eqref{eq:C} with:

\begin{align} \label{eq:C2}
	C = \gam C_{t-1} + n_t, \qquad n_t \overset{iid}{\sim} \text{Exponential}(\lam \Del)
\end{align}

\noindent where the only difference between Eq. \eqref{eq:C} and Eq. \eqref{eq:C2} is the distribution on $n_t$.  Plugging this change into Eq. \eqref{eq:naht3} yields
%, by replacing the Poisson distribution on $\bn$ with an exponential distribution. Plugging this approximation into Eq. \eqref{eq:nhat4} yields:

\begin{align} \label{eq:obj2}
\bn_{FAND} &= \argmax_{n_t>0 \, \forall t}  \sum_{t=1}^T \bigg( \frac{1}{2 \sig^2}(F_t - \alpha(C_t + \beta))^2  + n_t \lam \Del \bigg) %, \qquad n_t \overset{iid}{\sim} \text{Exponential}(\lam \Del) %\an  \sum_{t=1}^T \left( \frac{1}{2 \sig^2}(\norm{\bF_t -\balpha (C_t + \beta)}^2  +  n_t  \lam \Del \right).
\end{align}

\noindent where the constraint on $\bn$ has been relaxed from  $n_t \in \mathbb{N}_0$ to $n_t \geq 0$ (since the support of an exponential distribution is the non-negative number line).  Note that this is a common approximation technique in the machine learning literature \cite{HastieFriedman01}, as it is the closest convex relaxation to its non-convex counterpart. While this convex relaxation makes the problem tractable, the ``sharp'' threshold imposed by the non-negativity constraint prohibits the use of standard gradient ascent techniques \cite{BoydVandenberghe04}. We therefore take an ``interior-point'' (or ``barrier'') approach, in which we drop the sharp threshold, and add a barrier term, which must approach $-\infty$ as $n_t$ approaches zero (e.g., $-\log n_t$) \cite{BoydVandenberghe04}.  By iteratively reducing the weight of the barrier term, we are guaranteed to converge to the correct solution \cite{BoydVandenberghe04}.  Thus, our goal is to efficiently solve:

\begin{align} \label{eq:eta}
\hbn_{\zzz} &= \argmin_{n_t \forall t}  \sum_{t=1}^T \left( \frac{1}{2 \sig^2}(F_t - \alpha(C_t + \beta))^2  +  n_t  \lam \Del - \zzz \log(n_t) \right),
\end{align}

Since spikes and calcium are related to one another via a simple linear transformation, namely, $n_t= C_t-\gam C_{t-1}$, we may rewrite Eq. \eqref{eq:eta} in terms of $\bC$:

\begin{align} 
\hbC_{\zzz} &= \argmin_{C_t - \gamma C_{t-1} \geq 0 \forall t} \sum_{t=1}^{T} \left( \frac{1}{2 \sig^2} (F_t -\alpha (C_t + \beta))^2  + (C_t - \gamma C_{t-1}) \lam \Del - \zzz \log(C_t - \gamma C_{-1}) \right). \label{eq:eta2}
\end{align}

\noindent The concavity of Eq. \eqref{eq:eta2} facilitates utilizing any number of techniques guaranteed to find the global optimum.  The fact that the argument of Eq. \eqref{eq:eta2} is twice differentiable, suggests that we use the Newton-Raphson technique. Importantly, the state-space nature of this problem yields a particularly efficient approach. Specifically, note that the Hessian is \emph{tridiagonal}, which is clear upon rewriting \eqref{eq:eta2} in matrix notation:

\begin{align} 
\hbC_{\zzz} %&= \argmin_{C_t - \gamma C_{t-1} \geq 0 \forall t} \sum_{t=1}^{T} \left( \frac{1}{2 \sig^2}\norm{\bF_t -\balpha (C_t + \beta)}^2  + (C_t - \gamma C_{t-1}) \lam \Del - \zzz \log(C_t - \gamma C_{-1} -\nu ) \right) \nonumber \\
&= \az  \frac{1}{2 \sig^2} \norm{\bF - \alpha (\bC +\beta)}^2 + (\bM \bC )\T \blam  - \zzz \log(\bM \bC)\T\ve{1},  \label{eq:eta3}
\end{align}

\noindent where $\ve{M} \in \mathbb{R}^{T \times T}$ is a bidiagonal matrix, $\bM \bC \geq \ve{0}$ indicates that every element of $\bM \bC$ is greater than or equal to zero, $\T$ indicates transpose, $\ve{1}$ is a $T$ dimensional column vector, $\blam=\lam \Del \ve{1}\T$, and $\log(\cdot)$ indicates an element-wise logarithm.  Note that Eq. \eqref{eq:eta3} follows from writing $\bn$ in terms of $\bM$ and $\bC$:
 
% such as Newton-Raphson, which, na\"{i}ely, requires inverting the Hessian (second derivative), an $O(T^3)$ operation.  
%We have therefore reduced the computational burden from exponential to polynomial in $T$.   However, by utilizing the structure of Eq. \eqref{eq:trans}, we can devise an algorithm that further reduces computation burden from polynomial in $T$ to \emph{linear} in $T$.  In particular, we note here that 
%, or, in matrix notation: 

\begin{align} \label{eq:M}
\ve{M} \bC = %- \bb=
\begin{bmatrix}
1 & 0  & 0 & \cdots & \cdots \\
1 & -\gamma & 0 & \cdots & \cdots \\
0 & 1 & -\gamma & 0 & \cdots  \\
\vdots & \vdots & \vdots & \vdots & \vdots  \\
0 & 0 & 0 & 1 & -\gamma
\end{bmatrix}
\begin{bmatrix}
C_1 \\ C_2 \\ \vdots \\ \vdots \\ C_T  
\end{bmatrix}
%-\begin{bmatrix}
%\nu/\rho \\ \nu/\rho \\ \vdots \\ \vdots \\ \nu/\rho 
%\end{bmatrix}
= 
\begin{bmatrix}
n_1 \\ n_2 \\ \vdots \\ \vdots \\ n_T
\end{bmatrix}
= \bn
\end{align}

%\noindent and $\ve{M} \in \mathbb{R}^{T \times T}$ is a bidiagonal matrix. Given Eq. \eqref{eq:M}, we may rewrite Eq. \eqref{eq:eta} only in terms of $\bC$ (i.e., not $\bn$):
%
%\begin{subequations}  
%\begin{align} 
%\hbC_{\zzz} &= \argmin_{C_t - \gamma C_{t-1} \geq 0 \forall t} \sum_{t=1}^{T} \left( \frac{1}{2 \sig^2}\norm{\bF_t -\balpha (C_t + \beta)}^2  + (C_t - \gamma C_{t-1}) \lam \Del - \zzz \log(C_t - \gamma C_{-1} -\nu ) \right) \nonumber \\
%&= \az  \frac{1}{2 \sig^2} \norm{\bF - \balpha (\trans{\bC} +\beta+\ve{1}\T)}^2 + \lam \Del (\bM \bC )\T \ve{1}  - \zzz \log(\bM \bC)\T\ve{1},  \label{eq:eta2}
%\end{align}
%\end{subequations}

Thus, a little bit of calculus yields our update algorithm for $\bC_z$:

%As \eqref{eq:eta2} is concave (it is identical to Eq. \eqref{eq:eta} with different notation), we may use any descent technique to find $\hbC_{\zzz}$.  We elect to use the Newton-Raphson approach: 

%, i.e., update $\widehat{\ve{C}}_{\zzz}$ by adding to it the solution to $\ve{H}\ve{C} = \ve{g}$, weighted by $0<s\leq1$, where $\ve{H}$ and $\ve{g}$ are the Hessian and gradient of the argument in \eqref{eq:goal2}.  The step size, $s$, ensures that the posterior converges, by enforcing an increase in the objective with each step. Therefore, we have: 

\begin{subequations} \label{eq:NR}
\begin{align}
\hbC_{\zzz} &\leftarrow \hbC_{\zzz} + s \bd \\
\bH \bd &= \bg \\
\ve{g} &= -\frac{\alpha}{\sig^2}(\bF -\alpha({\hbC\T}_{\zzz} + \beta)) + \ve{M}\T\blam - \zzz \ve{M}\T (\ve{M} \hbC_{\zzz})^{-1} \label{eq:g} \\
\ve{H} &= \frac{\alpha^2}{\sig^2} \ve{I} + \zzz \ve{M}\T (\ve{M} \hbC_{\zzz})^{-2} \ve{M} \label{eq:H}
\end{align}
\end{subequations}

\noindent where $s$ is the step size, $\bd$ is the step direction, and $\bg$ and $\bH$ are the gradient (first derivative) and Hessian (second derivative) of the argument in Eq. \eqref{eq:eta3} with respect to $\bC$, respectively, and the exponents indicate element-wise operations. Note that we use ``backtracking linesearches'', meaning that for each iteration, we find the maximal $s$ that is (i) between $0$ and $1$ and (ii) decreases the likelihood.

Typically, implementing Newton-Raphson requires inverting the Hessian, i.e., $\bd = \bH^{-1} \bg$, a computation consuming $O(T^3)$ time. Already, this would be a drastic improvement over the most efficient algorithm assuming Poisson spikes, which require $O(k^T)$ time (where $k$ is the maximum number of spikes per frame).  Here, because $\ve{M}$ is bidiagonal, the Hessian is tridiagonal, the solution may be found in $O(T)$ time via standard banded Gaussian elimination techniques (which can be implemented efficiently in Matlab using $\bH \backslash \bg$). In other words, the above approximation and inference algorithm reduces computations from exponential time to \emph{linear} time. We refer to this fast algorithm for solving \eqref{eq:obj2} the FAst Nonnegative Deconvolution (FAND) filter. 


\paragraph{Fast Wiener Filter}

Instead of replacing the Poisson distribution on spikes with an exponential, we can replace it with a Gaussian:

 \begin{align} \label{eq:C3}
	C = \gam C_{t-1} + n_t, \qquad n_t \overset{iid}{\sim} \mN(\lam \Del, \lam \Del)
\end{align}

\noindent which, when plugged into Eq. \eqref{eq:nhat3} yields

\begin{align} \label{eq:obj3}
\bn_{Wiener} &= \argmax_{n_t}  \sum_{t=1}^T \bigg( \frac{1}{2 \sig^2}(F_t - \alpha(C_t + \beta))^2  + 
 \frac{1}{2 \lam \Del}(n_t - \lam \Del)^2\bigg) 
\end{align}

Using the same tridiagonal trick as above, we can solve Eq. \eqref{eq:obj3} using Newton-Raphson once (since we have a quadratic problem here, see Appendix \ref{sec:wiener} for details).  Because we know only positive spikes are possible, at times we will also consider, $[$Wiener$]_+$, which is the Wiener filter half-wave rectified, i.e., all sub-zero values are set to zero.  